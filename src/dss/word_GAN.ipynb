{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import *\n",
    "from preprocess import *\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "WORD_IMG_SHAPE = (64, 64 * 4)\n",
    "LATENT_SIZE = np.prod(WORD_IMG_SHAPE)\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = nn.Sequential(\n",
    "    # in: latent_size x 1 x 1\n",
    "\n",
    "    nn.ConvTranspose2d(LATENT_SIZE, 1024, kernel_size=4, stride=1, padding=0, bias=False),\n",
    "    nn.BatchNorm2d(1024),\n",
    "    nn.ReLU(True),\n",
    "    # out: 512 x 4 x 4\n",
    "\n",
    "    nn.ConvTranspose2d(1024, 512, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(512),\n",
    "    nn.ReLU(True),\n",
    "    # out: 256 x 8 x 8\n",
    "\n",
    "    nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(256),\n",
    "    nn.ReLU(True),\n",
    "    # out: 128 x 16 x 16\n",
    "\n",
    "    nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(128),\n",
    "    nn.ReLU(True),\n",
    "    # out: 64 x 32 x 32\n",
    "    \n",
    "    nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.ReLU(True),\n",
    "    # out: 64 x 32 x 32\n",
    "\n",
    "    nn.ConvTranspose2d(64, 1, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    nn.Tanh(),\n",
    "    # out: 1 x 64 x 64\n",
    "    \n",
    "    Reshape('0', 1, '2*3')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dir = 'generated'\n",
    "os.makedirs(sample_dir, exist_ok=True)\n",
    "\n",
    "def save_samples(index, latent_tensors, show=True, num_samples=3*8):\n",
    "    fake_images = generator(latent_tensors)\n",
    "    fake_fname = 'generated-images-{0:0=4d}.png'.format(index)\n",
    "    save_image(fake_images.reshape((num_samples, 1, *WORD_IMG_SHAPE)), os.path.join(sample_dir, fake_fname), nrow=3, pad_value=1)\n",
    "    print('Saving', fake_fname)\n",
    "    if show:\n",
    "        fig, ax = plt.subplots(figsize=(8, 8))\n",
    "        ax.set_xticks([]); ax.set_yticks([])\n",
    "        ax.imshow(make_grid(fake_images.cpu().detach(), nrow=12).permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_generator(opt_g, base_imgs, crpt_imgs):\n",
    "    batch_size = base_imgs.shape[0]\n",
    "    # Clear generator gradients\n",
    "    opt_g.zero_grad()\n",
    "    \n",
    "    # Generate fake images\n",
    "    # latent = torch.randn(batch_size, latent_size, 1, 1)\n",
    "    # corrupted, base, labels = next(cwg)\n",
    "    # print(np.shape(crpt_imgs))\n",
    "    # print(np.shape(crpt_imgs[0]))\n",
    "    # print(type(crpt_imgs))\n",
    "    # print(crpt_imgs.reshape((BATCH_SIZE, LATENT_SIZE, 1, 1)).shape)\n",
    "    rest_imgs = generator(crpt_imgs.reshape((batch_size, LATENT_SIZE, 1, 1)))\n",
    "    # print(f\"rest img shape: {rest_imgs.shape}\")\n",
    "    # Try to fool the discriminator\n",
    "    # fool_preds = discriminator(fake_images)\n",
    "    # fool_targets = torch.ones(batch_size, 1)\n",
    "    # fool_loss = F.mse_loss(fool_preds, fool_targets)\n",
    "    \n",
    "    sim_loss = F.mse_loss((rest_imgs / 2), base_imgs.reshape((batch_size, 1, LATENT_SIZE)) / 2)\n",
    "    print(f\"loss shape: {sim_loss.shape}\")\n",
    "    sim_loss += 0.2 * (-torch.flatten(rest_imgs) + 1)\n",
    "    \n",
    "    # Update generator weights\n",
    "    # loss = 2.5 * fool_loss + 150 * sim_loss\n",
    "    loss = 150 * sim_loss\n",
    "    loss.backward()\n",
    "    opt_g.step()\n",
    "    \n",
    "    print(f\"generator loss: {(torch.mean(loss).item())}\")\n",
    "    \n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = 3*8\n",
    "\n",
    "data_loader = DataLoader(load_dataset('char', equal_shapes=False), shuffle=True, num_workers=0, pin_memory=True)\n",
    "cwg = CorruptWordGen(data_loader, batch_size=num_examples, img_shape=WORD_IMG_SHAPE)\n",
    "\n",
    "fixed_base, fixed_corrupted, fixed_labels = next(cwg)\n",
    "fixed_corrupted = fixed_corrupted.reshape((num_examples, LATENT_SIZE, 1, 1))\n",
    "\n",
    "def fit(epochs, lr, start_idx=1):\n",
    "  torch.cuda.empty_cache()\n",
    "    \n",
    "  # Losses & scores\n",
    "  losses_g = []\n",
    "  losses_d = []\n",
    "  real_scores = []\n",
    "  fake_scores = []\n",
    "  gen_scores = []\n",
    "  \n",
    "  # Create optimizers\n",
    "  # opt_d = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "  opt_g = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "  \n",
    "  for epoch in range(epochs):\n",
    "    data_loader = DataLoader(load_dataset('char', equal_shapes=False), shuffle=True, num_workers=0, pin_memory=True)\n",
    "    cwg = PrettyCorruptWordGen(data_loader, batch_size=32, img_shape=WORD_IMG_SHAPE)\n",
    "    \n",
    "    for base_imgs, crpt_imgs, labels in tqdm(cwg):\n",
    "      \n",
    "      # # Train discriminator\n",
    "      # loss_d, real_score, fake_score = train_discriminator(real_images, opt_d)\n",
    "      # # Train generator\n",
    "      loss_g = train_generator(opt_g, base_imgs, crpt_imgs)\n",
    "        \n",
    "    # Record losses & scores\n",
    "    losses_g.append(loss_g)\n",
    "    # losses_d.append(loss_d)\n",
    "    # real_scores.append(real_score)\n",
    "    # fake_scores.append(fake_score)\n",
    "    \n",
    "    # Log losses & scores (last batch)\n",
    "    print(\"Epoch [{}/{}], loss_g: {:.4f}\".format(\n",
    "      epoch+1, epochs, loss_g))\n",
    "\n",
    "    # Save generated images\n",
    "    save_samples(epoch+start_idx, fixed_corrupted, show=False, num_samples = num_examples)\n",
    "  \n",
    "  return losses_g, losses_d, real_scores, fake_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11, 23, 21, 4, 11, 20], [16, 16, 16], [21, 6, 9, 20], [21, 13, 10, 4, 11], [7, 6, 20, 12, 11, 17, 19, 16], [18, 1, 1, 1, 6, 21, 23, 0], [4, 9, 19], [14, 10, 7, 2, 23, 20], [1, 1, 18, 24, 19, 12, 7, 2], [5, 10, 10, 19, 11, 2], [0, 5, 2, 6, 0, 20, 12], [19, 16, 23, 16, 10, 10, 20, 13], [6, 6, 23, 11], [7, 6], [18, 1], [0, 16, 6, 5, 13, 18, 9, 15, 1], [5, 11, 2, 6, 16, 4, 20], [22, 9, 18, 1, 3, 23], [21, 6, 21], [6, 9, 20, 13], [21, 16, 21, 20, 18], [6, 10, 11, 20, 18, 9], [16, 6, 18, 20, 1], [4, 2, 6, 7, 18, 0, 6, 4, 1]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# print(torch.cat(fixed_base).shape)\n",
    "# print(np.shape(fixed_base[0]))\n",
    "# print(np.shape(fixed_corrupted[0]))\n",
    "save_image(fixed_base.reshape((num_examples, 1, *WORD_IMG_SHAPE)), os.path.join('generated', \"base.png\"), nrow=3, pad_value=1)\n",
    "save_image(fixed_corrupted.reshape((num_examples, 1, *WORD_IMG_SHAPE)), os.path.join('generated', \"corrupted.png\"), nrow=3, pad_value=1)\n",
    "print(fixed_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving generated-images-0000.png\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3670bbce3a7d4f119fa7fcf5bd292489",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss shape: torch.Size([])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "output with shape [] doesn't match the broadcast shape [524288]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3156/1850125721.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msave_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfixed_corrupted\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_examples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1e-2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3156/2396760100.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(epochs, lr, start_idx)\u001b[0m\n\u001b[0;32m     30\u001b[0m       \u001b[1;31m# loss_d, real_score, fake_score = train_discriminator(real_images, opt_d)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m       \u001b[1;31m# # Train generator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m       \u001b[0mloss_g\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopt_g\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbase_imgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcrpt_imgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;31m# Record losses & scores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3156/3459481512.py\u001b[0m in \u001b[0;36mtrain_generator\u001b[1;34m(opt_g, base_imgs, crpt_imgs)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0msim_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrest_imgs\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbase_imgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLATENT_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"loss shape: {sim_loss.shape}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0msim_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m0.2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrest_imgs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;31m# Update generator weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: output with shape [] doesn't match the broadcast shape [524288]"
     ]
    }
   ],
   "source": [
    "save_samples(0, fixed_corrupted, show=False, num_samples = num_examples)\n",
    "history = fit(100, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cf92aa13fedf815d5c8dd192b8d835913fde3e8bc926b2a0ad6cc74ef2ba3ca2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
