{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as tt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.nn.functional as F\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "from math import prod\n",
    "from util import img_distance\n",
    "import json\n",
    "\n",
    "# %matplotlib inline\n",
    "torch.cuda.set_device(0)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../../data/dss/\"\n",
    "CHAR_DATA_DIR = DATA_DIR + \"monkbrill/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 64\n",
    "batch_size = 128\n",
    "latent_size = image_size ** 2\n",
    "stats = (0.5,), (0.5,)\n",
    "\n",
    "train_ds = ImageFolder(CHAR_DATA_DIR, transform=tt.Compose([tt.Grayscale(num_output_channels=1),\n",
    "                                                            tt.RandomInvert(p=1),\n",
    "                                                            tt.Resize(image_size),\n",
    "                                                            tt.CenterCrop(image_size),\n",
    "                                                            tt.ToTensor(),\n",
    "                                                            tt.Normalize(*stats)]))\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in iter(DataLoader(train_ds, 1, shuffle=True, num_workers=3, pin_memory=True)):\n",
    "#   print(x[0][0][0])\n",
    "#   print([y.shape for y in x])\n",
    "#   plt.imshow(x[0][0][0])\n",
    "#   break\n",
    "\n",
    "class CorruptCharGen():\n",
    "  \n",
    "  def __init__(self, *args, max_iter=2048, **kwargs):\n",
    "    self.dl_args = args\n",
    "    self.dl_kwargs = {**kwargs, \"batch_size\": 1}\n",
    "    self.n_iter = 0\n",
    "    self.max_iter = max_iter\n",
    "    self.data_loader = None\n",
    "  \n",
    "  def __iter__(self):\n",
    "    self.n_iter = 0\n",
    "    self.data_loader = None\n",
    "    return self\n",
    "  \n",
    "  def __next__(self):\n",
    "    if self.n_iter > self.max_iter:\n",
    "      raise StopIteration\n",
    "    \n",
    "    if self.data_loader is None:\n",
    "      self.data_loader = iter(DataLoader(*self.dl_args, **self.dl_kwargs))\n",
    "    \n",
    "    try:\n",
    "      base_img = next(self.data_loader)\n",
    "      base_img_lab = base_img[1]\n",
    "      base_img = base_img[0][0][0]\n",
    "      subtr_img = next(self.data_loader)[0][0][0]\n",
    "      crpt_img = base_img - (subtr_img + 1)\n",
    "      crpt_img = torch.maximum(crpt_img, -torch.ones(*crpt_img.shape))\n",
    "      # temp = subtr_img + 1\n",
    "      # print((torch.min(temp), torch.max(temp)))\n",
    "      \n",
    "      # fig, axes = plt.subplots(1, 3, figsize=(20, 60))\n",
    "      # axes[0].imshow(base_img)\n",
    "      # axes[1].imshow(subtr_img)\n",
    "      # axes[2].imshow(crpt_img)\n",
    "      \n",
    "      # plt.show()\n",
    "      \n",
    "      self.n_iter += 1\n",
    "      \n",
    "      return crpt_img.reshape((latent_size, 1, 1)), base_img.reshape((latent_size, 1, 1)), base_img_lab\n",
    "      \n",
    "    except StopIteration:\n",
    "      self.data_loader = None\n",
    "      return next(self)\n",
    "    \n",
    "  def gen_chars(self, num=1):\n",
    "    crpt_imgs = [next(self) for _ in range(num)]\n",
    "    return tuple([torch.stack([img[i] for img in crpt_imgs]) for i in range(len(crpt_imgs[0]))])\n",
    "  \n",
    "  # torch.stack([img[0] for img in crpt_imgs]), \\\n",
    "  #          torch.stack([])\n",
    "  #          torch.stack([img[1] for img in crpt_imgs])\n",
    "      \n",
    "    \n",
    "ccg = CorruptCharGen(deepcopy(train_ds), shuffle=True, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(ccg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reshape(nn.Module):\n",
    "  \n",
    "  def __init__(self, *shape):\n",
    "    super(Reshape, self).__init__()\n",
    "    \n",
    "    if isinstance(shape[0], tuple):\n",
    "      shape = shape[0]\n",
    "      \n",
    "    self.shape = shape\n",
    "    \n",
    "  def forward(self, input):\n",
    "    relative_dim = lambda x: input.shape[int(x)]\n",
    "    shape = tuple([prod(map(relative_dim, d.split(\"*\"))) if isinstance(d, str) else d for d in self.shape])\n",
    "    return input.reshape(shape)\n",
    "\n",
    "\n",
    "generator = nn.Sequential(\n",
    "    # in: latent_size x 1 x 1\n",
    "\n",
    "    nn.ConvTranspose2d(latent_size, 512, kernel_size=4, stride=1, padding=0, bias=False),\n",
    "    nn.BatchNorm2d(512),\n",
    "    nn.ReLU(True),\n",
    "    # out: 512 x 4 x 4\n",
    "\n",
    "    nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(256),\n",
    "    nn.ReLU(True),\n",
    "    # out: 256 x 8 x 8\n",
    "\n",
    "    nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(128),\n",
    "    nn.ReLU(True),\n",
    "    # out: 128 x 16 x 16\n",
    "\n",
    "    nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.ReLU(True),\n",
    "    # out: 64 x 32 x 32\n",
    "\n",
    "    nn.ConvTranspose2d(64, 1, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    nn.Tanh(),\n",
    "    # out: 1 x 64 x 64\n",
    "    \n",
    "    # Reshape(1, 1, '2*3')\n",
    ")\n",
    "c, b, l = ccg.gen_chars(1)\n",
    "\n",
    "output = generator(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4096, 1, 1])\n",
      "torch.Size([1, 1, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "print(c.shape)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = nn.Sequential(\n",
    "    # in: 1 x 64 x 64\n",
    "\n",
    "    nn.Conv2d(1, 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.LeakyReLU(0.2, inplace=True),\n",
    "    # out: 64 x 32 x 32\n",
    "\n",
    "    nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(128),\n",
    "    nn.LeakyReLU(0.2, inplace=True),\n",
    "    # out: 128 x 16 x 16\n",
    "\n",
    "    nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(256),\n",
    "    nn.LeakyReLU(0.2, inplace=True),\n",
    "    # out: 256 x 8 x 8\n",
    "\n",
    "    nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(512),\n",
    "    nn.LeakyReLU(0.2, inplace=True),\n",
    "    # out: 512 x 4 x 4\n",
    "\n",
    "    nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=0, bias=False),\n",
    "    # out: 1 x 1 x 1\n",
    "\n",
    "    nn.Flatten(),\n",
    "    nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "denorm = lambda x: x\n",
    "\n",
    "sample_dir = 'generated'\n",
    "os.makedirs(sample_dir, exist_ok=True)\n",
    "\n",
    "def save_samples(index, latent_tensors, show=True):\n",
    "    fake_images = generator(latent_tensors)\n",
    "    fake_fname = 'generated-images-{0:0=4d}.png'.format(index)\n",
    "    save_image(denorm(fake_images), os.path.join(sample_dir, fake_fname), nrow=8)\n",
    "    print('Saving', fake_fname)\n",
    "    if show:\n",
    "        fig, ax = plt.subplots(figsize=(8, 8))\n",
    "        ax.set_xticks([]); ax.set_yticks([])\n",
    "        ax.imshow(make_grid(fake_images.cpu().detach(), nrow=8).permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 2070'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 0\n",
    "\n",
    "def train_discriminator(real_images, opt_d):\n",
    "    # Clear discriminator gradients\n",
    "    opt_d.zero_grad()\n",
    "\n",
    "    # Pass real images through discriminator\n",
    "    real_preds = discriminator(real_images)\n",
    "    real_targets = torch.ones(real_images.size(0), 1)\n",
    "    # real_loss = F.binary_cross_entropy(real_preds, real_targets)\n",
    "    real_loss = F.mse_loss(real_preds, real_targets)\n",
    "    real_score = torch.mean(real_preds).item()\n",
    "    \n",
    "    # Generate fake images\n",
    "    # latent = torch.randn(batch_size, latent_size, 1, 1)\n",
    "    corrupted, base, labels = ccg.gen_chars(batch_size)\n",
    "    fake_images = generator(corrupted)\n",
    "\n",
    "    # Pass fake images through discriminator\n",
    "    fake_targets = torch.zeros(fake_images.size(0), 1)\n",
    "    fake_preds = discriminator(fake_images)\n",
    "    # fake_loss = F.binary_cross_entropy(fake_preds, fake_targets)\n",
    "    fake_loss = F.mse_loss(fake_preds, fake_targets)\n",
    "    fake_score = torch.mean(fake_preds).item()\n",
    "    \n",
    "    # if real_loss < 0.1:\n",
    "    #   print(f\"\\nreal:\\n{real_preds[:10]}\\n{real_targets[:10]}\")\n",
    "    # if fake_loss < 0.1:\n",
    "    #   print(f\"\\nfake:\\n{fake_preds[:10]}\\n{fake_targets[:10]}\")\n",
    "    \n",
    "    print(f\"discriminator losses: {(real_loss.item(), fake_loss.item())}\")\n",
    "\n",
    "    # Update discriminator weights\n",
    "    loss = (real_loss + fake_loss) / 2\n",
    "    loss.backward()\n",
    "    opt_d.step()\n",
    "    return loss.item(), real_score, fake_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(pred, true):\n",
    "  return F.l1_loss(pred, true) / latent_size\n",
    "\n",
    "def train_generator(opt_g):\n",
    "    # Clear generator gradients\n",
    "    opt_g.zero_grad()\n",
    "    \n",
    "    # Generate fake images\n",
    "    # latent = torch.randn(batch_size, latent_size, 1, 1)\n",
    "    corrupted, base, labels = ccg.gen_chars(batch_size)\n",
    "    # print(f\"fixable images shape: {corrupted.shape}\")\n",
    "    fake_images = generator(corrupted)\n",
    "    \n",
    "    # Try to fool the discriminator\n",
    "    fool_preds = discriminator(fake_images)\n",
    "    fool_targets = torch.ones(batch_size, 1)\n",
    "    fool_loss = F.mse_loss(fool_preds, fool_targets)\n",
    "    \n",
    "    sim_loss = F.mse_loss((fake_images / 2).reshape((batch_size, latent_size, 1, 1)), base / 2)\n",
    "    \n",
    "    # Update generator weights\n",
    "    loss = 2.5 * fool_loss + 150 * sim_loss\n",
    "    loss.backward()\n",
    "    opt_g.step()\n",
    "    \n",
    "    # target_dist = img_distance(fake_images.detach().numpy(), base.detach().numpy())\n",
    "    # crpt_dist = img_distance(fake_images.detach().numpy(), corrupted.detach().numpy())\n",
    "    \n",
    "    print(f\"generator loss: {(torch.mean(loss).item())}\")\n",
    "    \n",
    "    return loss.item(), None, None#, target_dist, crpt_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixed_latent = torch.randn(batch_size, latent_size, 1, 1)\n",
    "fixed_corrupted, fixed_base, fixed_labels = ccg.gen_chars(128)\n",
    "\n",
    "def fit(epochs, lr, start_idx=1):\n",
    "  torch.cuda.empty_cache()\n",
    "  \n",
    "  # Losses & scores\n",
    "  losses_g = []\n",
    "  losses_d = []\n",
    "  real_scores = []\n",
    "  fake_scores = []\n",
    "  target_distances = []\n",
    "  crpt_distances = []\n",
    "  \n",
    "  # Create optimizers\n",
    "  opt_d = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "  opt_g = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "  \n",
    "  for epoch in range(epochs):\n",
    "    target_distances.append([])\n",
    "    crpt_distances.append([])\n",
    "  \n",
    "    for real_images, _ in tqdm(train_dl):\n",
    "      iter(ccg)\n",
    "      \n",
    "      generator.zero_grad()\n",
    "      discriminator.zero_grad()\n",
    "      \n",
    "      # Train discriminator\n",
    "      loss_d, real_score, fake_score = train_discriminator(real_images, opt_d)\n",
    "      # Train generator\n",
    "      loss_g, target_dist, crpt_dist = train_generator(opt_g)\n",
    "      \n",
    "      fixed_predicted = generator(fixed_corrupted)\n",
    "      target_dist = img_distance(fixed_predicted.detach().numpy(), fixed_base.detach().numpy())\n",
    "      crpt_dist = img_distance(fixed_predicted.detach().numpy(), fixed_corrupted.detach().numpy())\n",
    "      \n",
    "      print(f\"td: {target_dist} | cd: {crpt_dist}\")\n",
    "      target_distances[-1].append(float(target_dist))\n",
    "      crpt_distances[-1].append(float(crpt_dist))\n",
    "      \n",
    "      with open('./trained/char/scores.json', \"w+\") as file:\n",
    "        json.dump({\"target\": target_distances, \"corrupt\": crpt_distances}, file)\n",
    "          \n",
    "          \n",
    "          \n",
    "    # Record losses & scores\n",
    "    losses_g.append(loss_g)\n",
    "    losses_d.append(loss_d)\n",
    "    real_scores.append(real_score)\n",
    "    fake_scores.append(fake_score)\n",
    "      \n",
    "    # Log losses & scores (last batch)\n",
    "    print(\"Epoch [{}/{}], loss_g: {:.4f}, loss_d: {:.4f}, real_score: {:.4f}, fake_score: {:.4f}\".format(\n",
    "      epoch+1, epochs, loss_g, loss_d, real_score, fake_score))\n",
    "\n",
    "    # Save generated images\n",
    "    save_samples(epoch+start_idx, fixed_corrupted, show=False)\n",
    "  \n",
    "  return losses_g, losses_d, real_scores, fake_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image('./generated/generated-images-0060.png')\n",
    "save_image(denorm(fixed_base.reshape(128, 1, image_size, image_size)), os.path.join('generated', \"base.png\"), nrow=8)\n",
    "save_image(denorm(fixed_corrupted.reshape(128, 1, image_size, image_size)), os.path.join('generated', \"corrupted.png\"), nrow=8)\n",
    "print(fixed_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = fit(100, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'opt_d' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23304/1757241822.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"./trained/char/discriminator\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"./trained/char/generator\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopt_d\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"./trained/char/opt_d\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopt_g\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"./trained/char/opt_g\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'opt_d' is not defined"
     ]
    }
   ],
   "source": [
    "torch.save(discriminator.state_dict(), \"./trained/char/discriminator\")\n",
    "torch.save(generator.state_dict(), \"./trained/char/generator\")\n",
    "torch.save(opt_d.state_dict(), \"./trained/char/opt_d\")\n",
    "torch.save(opt_g.state_dict(), \"./trained/char/opt_g\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cf92aa13fedf815d5c8dd192b8d835913fde3e8bc926b2a0ad6cc74ef2ba3ca2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
