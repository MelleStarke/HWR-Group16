{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as tt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.nn.functional as F\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "\n",
    "# %matplotlib inline\n",
    "torch.cuda.set_device(0)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../../data/dss/\"\n",
    "CHAR_DATA_DIR = DATA_DIR + \"monkbrill/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 64\n",
    "batch_size = 256\n",
    "latent_size = image_size ** 2\n",
    "stats = (0.5,), (0.5,)\n",
    "\n",
    "train_ds = ImageFolder(CHAR_DATA_DIR, transform=tt.Compose([tt.Grayscale(num_output_channels=1),\n",
    "                                                            tt.RandomInvert(p=1),\n",
    "                                                            tt.Resize(image_size),\n",
    "                                                            tt.CenterCrop(image_size),\n",
    "                                                            tt.ToTensor(),\n",
    "                                                            tt.Normalize(*stats)]))\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in iter(DataLoader(train_ds, 1, shuffle=True, num_workers=3, pin_memory=True)):\n",
    "#   print(x[0][0][0])\n",
    "#   print([y.shape for y in x])\n",
    "#   plt.imshow(x[0][0][0])\n",
    "#   break\n",
    "\n",
    "class CorruptCharGen():\n",
    "  \n",
    "  def __init__(self, *args, max_iter=2048, **kwargs):\n",
    "    self.dl_args = args\n",
    "    self.dl_kwargs = {**kwargs, \"batch_size\": 1}\n",
    "    self.n_iter = 0\n",
    "    self.max_iter = max_iter\n",
    "    self.data_loader = None\n",
    "  \n",
    "  def __iter__(self):\n",
    "    self.n_iter = 0\n",
    "    self.data_loader = None\n",
    "    return self\n",
    "  \n",
    "  def __next__(self):\n",
    "    if self.n_iter > self.max_iter:\n",
    "      raise StopIteration\n",
    "    \n",
    "    if self.data_loader is None:\n",
    "      self.data_loader = iter(DataLoader(*self.dl_args, **self.dl_kwargs))\n",
    "    \n",
    "    try:\n",
    "      base_img = next(self.data_loader)\n",
    "      base_img_lab = base_img[1]\n",
    "      base_img = base_img[0][0][0]\n",
    "      subtr_img = next(self.data_loader)[0][0][0]\n",
    "      crpt_img = base_img - (subtr_img + 1)\n",
    "      crpt_img = torch.maximum(crpt_img, -torch.ones(*crpt_img.shape))\n",
    "      # temp = subtr_img + 1\n",
    "      # print((torch.min(temp), torch.max(temp)))\n",
    "      \n",
    "      # fig, axes = plt.subplots(1, 3, figsize=(20, 60))\n",
    "      # axes[0].imshow(base_img)\n",
    "      # axes[1].imshow(subtr_img)\n",
    "      # axes[2].imshow(crpt_img)\n",
    "      \n",
    "      # plt.show()\n",
    "      \n",
    "      self.n_iter += 1\n",
    "      \n",
    "      return crpt_img.reshape((latent_size, 1, 1)), base_img.reshape((latent_size, 1, 1)), base_img_lab\n",
    "      \n",
    "    except StopIteration:\n",
    "      self.data_loader = None\n",
    "      return next(self)\n",
    "    \n",
    "  def gen_chars(self, num=1):\n",
    "    crpt_imgs = [next(self) for _ in range(num)]\n",
    "    return tuple([torch.stack([img[i] for img in crpt_imgs]) for i in range(len(crpt_imgs[0]))])\n",
    "  \n",
    "  # torch.stack([img[0] for img in crpt_imgs]), \\\n",
    "  #          torch.stack([])\n",
    "  #          torch.stack([img[1] for img in crpt_imgs])\n",
    "      \n",
    "    \n",
    "ccg = CorruptCharGen(deepcopy(train_ds), shuffle=True, num_workers=0, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(ccg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = nn.Sequential(\n",
    "    # in: latent_size x 1 x 1\n",
    "\n",
    "    nn.ConvTranspose2d(latent_size, 512, kernel_size=4, stride=1, padding=0, bias=False),\n",
    "    nn.BatchNorm2d(512),\n",
    "    nn.ReLU(True),\n",
    "    # out: 512 x 4 x 4\n",
    "\n",
    "    nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(256),\n",
    "    nn.ReLU(True),\n",
    "    # out: 256 x 8 x 8\n",
    "\n",
    "    nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(128),\n",
    "    nn.ReLU(True),\n",
    "    # out: 128 x 16 x 16\n",
    "\n",
    "    nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.ReLU(True),\n",
    "    # out: 64 x 32 x 32\n",
    "\n",
    "    nn.ConvTranspose2d(64, 1, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    nn.Tanh()\n",
    "    # out: 1 x 64 x 64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = nn.Sequential(\n",
    "    # in: 1 x 64 x 64\n",
    "\n",
    "    nn.Conv2d(1, 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.LeakyReLU(0.2, inplace=True),\n",
    "    # out: 64 x 32 x 32\n",
    "\n",
    "    nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(128),\n",
    "    nn.LeakyReLU(0.2, inplace=True),\n",
    "    # out: 128 x 16 x 16\n",
    "\n",
    "    nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(256),\n",
    "    nn.LeakyReLU(0.2, inplace=True),\n",
    "    # out: 256 x 8 x 8\n",
    "\n",
    "    nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(512),\n",
    "    nn.LeakyReLU(0.2, inplace=True),\n",
    "    # out: 512 x 4 x 4\n",
    "\n",
    "    nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=0, bias=False),\n",
    "    # out: 1 x 1 x 1\n",
    "\n",
    "    nn.Flatten(),\n",
    "    nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "denorm = lambda x: x\n",
    "\n",
    "sample_dir = 'generated'\n",
    "os.makedirs(sample_dir, exist_ok=True)\n",
    "\n",
    "def save_samples(index, latent_tensors, show=True):\n",
    "    fake_images = generator(latent_tensors)\n",
    "    fake_fname = 'generated-images-{0:0=4d}.png'.format(index)\n",
    "    save_image(denorm(fake_images), os.path.join(sample_dir, fake_fname), nrow=8)\n",
    "    print('Saving', fake_fname)\n",
    "    if show:\n",
    "        fig, ax = plt.subplots(figsize=(8, 8))\n",
    "        ax.set_xticks([]); ax.set_yticks([])\n",
    "        ax.imshow(make_grid(fake_images.cpu().detach(), nrow=8).permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 2070'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 0\n",
    "\n",
    "def train_discriminator(real_images, opt_d):\n",
    "    # Clear discriminator gradients\n",
    "    opt_d.zero_grad()\n",
    "\n",
    "    # Pass real images through discriminator\n",
    "    real_preds = discriminator(real_images)\n",
    "    real_targets = torch.ones(real_images.size(0), 1)\n",
    "    # real_loss = F.binary_cross_entropy(real_preds, real_targets)\n",
    "    real_loss = F.mse_loss(real_preds, real_targets)\n",
    "    real_score = torch.mean(real_preds).item()\n",
    "    \n",
    "    # Generate fake images\n",
    "    # latent = torch.randn(batch_size, latent_size, 1, 1)\n",
    "    corrupted, base, labels = ccg.gen_chars(batch_size)\n",
    "    fake_images = generator(corrupted)\n",
    "\n",
    "    # Pass fake images through discriminator\n",
    "    fake_targets = torch.zeros(fake_images.size(0), 1)\n",
    "    fake_preds = discriminator(fake_images)\n",
    "    # fake_loss = F.binary_cross_entropy(fake_preds, fake_targets)\n",
    "    fake_loss = F.mse_loss(fake_preds, fake_targets)\n",
    "    fake_score = torch.mean(fake_preds).item()\n",
    "    \n",
    "    # if real_loss < 0.1:\n",
    "    #   print(f\"\\nreal:\\n{real_preds[:10]}\\n{real_targets[:10]}\")\n",
    "    # if fake_loss < 0.1:\n",
    "    #   print(f\"\\nfake:\\n{fake_preds[:10]}\\n{fake_targets[:10]}\")\n",
    "    \n",
    "    # print((real_loss.item(), fake_loss.item()))\n",
    "\n",
    "    # Update discriminator weights\n",
    "    loss = (real_loss + fake_loss) / 2\n",
    "    loss.backward()\n",
    "    opt_d.step()\n",
    "    return loss.item(), real_score, fake_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(pred, true):\n",
    "  return F.l1_loss(pred, true) / latent_size\n",
    "\n",
    "def train_generator(opt_g):\n",
    "    # Clear generator gradients\n",
    "    opt_g.zero_grad()\n",
    "    \n",
    "    # Generate fake images\n",
    "    # latent = torch.randn(batch_size, latent_size, 1, 1)\n",
    "    corrupted, base, labels = ccg.gen_chars(batch_size)\n",
    "    fake_images = generator(corrupted)\n",
    "    \n",
    "    # Try to fool the discriminator\n",
    "    fool_preds = discriminator(fake_images)\n",
    "    fool_targets = torch.ones(batch_size, 1)\n",
    "    fool_loss = F.mse_loss(fool_preds, fool_targets)\n",
    "    \n",
    "    sim_loss = mae(fake_images.reshape((batch_size, latent_size, 1, 1)), base)\n",
    "    \n",
    "    # Update generator weights\n",
    "    loss = 2.5 * fool_loss + 100 * sim_loss\n",
    "    loss.backward()\n",
    "    opt_g.step()\n",
    "    \n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixed_latent = torch.randn(batch_size, latent_size, 1, 1)\n",
    "fixed_corrupted, fixed_base, labels = ccg.gen_chars(64)\n",
    "\n",
    "def fit(epochs, lr, start_idx=1):\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # Losses & scores\n",
    "    losses_g = []\n",
    "    losses_d = []\n",
    "    real_scores = []\n",
    "    fake_scores = []\n",
    "    \n",
    "    # Create optimizers\n",
    "    opt_d = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "    opt_g = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for real_images, _ in tqdm(train_dl):\n",
    "            iter(ccg)\n",
    "            # Train discriminator\n",
    "            loss_d, real_score, fake_score = train_discriminator(real_images, opt_d)\n",
    "            # Train generator\n",
    "            loss_g = train_generator(opt_g)\n",
    "            \n",
    "        # Record losses & scores\n",
    "        losses_g.append(loss_g)\n",
    "        losses_d.append(loss_d)\n",
    "        real_scores.append(real_score)\n",
    "        fake_scores.append(fake_score)\n",
    "        \n",
    "        # Log losses & scores (last batch)\n",
    "        print(\"Epoch [{}/{}], loss_g: {:.4f}, loss_d: {:.4f}, real_score: {:.4f}, fake_score: {:.4f}\".format(\n",
    "            epoch+1, epochs, loss_g, loss_d, real_score, fake_score))\n",
    "    \n",
    "        # Save generated images\n",
    "        save_samples(epoch+start_idx, fixed_corrupted, show=False)\n",
    "    \n",
    "    return losses_g, losses_d, real_scores, fake_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aacea65ccad4c7a8618990edf7f1071",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], loss_g: 0.0158, loss_d: 0.5003, real_score: 0.9972, fake_score: 1.0000\n",
      "Saving generated-images-0001.png\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cac68ee103d47dfa735a4e9742e8379",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/100], loss_g: 0.0115, loss_d: 0.5000, real_score: 0.9999, fake_score: 1.0000\n",
      "Saving generated-images-0002.png\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "053fdc7d7e2d4bc59c771a5ec4002bc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/100], loss_g: 0.0094, loss_d: 0.5000, real_score: 0.9998, fake_score: 1.0000\n",
      "Saving generated-images-0003.png\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23ff31f1078849dd84da4f69d3126ffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/100], loss_g: 0.0083, loss_d: 0.5000, real_score: 0.9998, fake_score: 1.0000\n",
      "Saving generated-images-0004.png\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a9c382260fe4b8ba6dedc3f9be5f7fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = fit(100, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image('./generated/generated-images-0060.png')\n",
    "save_image(denorm(fixed_corrupted), os.path.join('generated', \"corrupted.png\"), nrow=8)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cf92aa13fedf815d5c8dd192b8d835913fde3e8bc926b2a0ad6cc74ef2ba3ca2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
